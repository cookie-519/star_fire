from collections import defaultdict
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib
import json
import requests
import pytesseract
from PIL import Image
from kimi_api import ask_kimi
from utils.report_generator import generate_learning_report
import pandas as pd
import matplotlib.font_manager as fm
import os
import easyocr
import io
from io import BytesIO


# è®¾ç½® pytesseract è·¯å¾„
pytesseract.pytesseract.tesseract_cmd = r"E:\Tesseract-OCR\tesseract.exe"

# è®¾ç½®å­—ä½“
fm.fontManager.addfont('SimHei.ttf')  # ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰ç›®å½•
matplotlib.rcParams["font.family"] = ("SimHei")
matplotlib.rcParams["axes.unicode_minus"] = False

DATA_PATH = "data/user_data.json"


# Kimi API è¯·æ±‚å‡½æ•°
def analyze_mistakes_with_kimi(mistake_text):
    url = "https://api.moonshot.cn/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "sk-I0dxd07uFwsojf6460SVpMDBG3d2jGLgqtyBwD2WjcJeJ6vd"
    }
    data = {
        "model": "moonshot-v1-8k",
        "messages": [
            {"role": "system",
             "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šå­¦ä¹ å¯¼å¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹é”™é¢˜å†…å®¹ï¼Œæ‰¾å‡ºå­¦ç”Ÿçš„å…±æ€§é—®é¢˜ã€è–„å¼±çŸ¥è¯†ç‚¹ï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ï¼Œå°½é‡ç²¾ç‚¼ä¸”å®ç”¨ã€‚"},
            {"role": "user", "content": mistake_text}
        ]
    }
    try:
        for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
            res = requests.post(url, json=data, headers=headers)
            if res.status_code == 200:
                return res.json()["choices"][0]["message"]["content"]
            else:
                print(f"Request failed with status code {res.status_code}. Retrying...")
                time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
        return "âŒ é”™é¢˜åˆ†æå¤±è´¥ï¼šæœåŠ¡å™¨æœªå“åº”"
    except Exception as e:
        return f"âŒ é”™é¢˜åˆ†æå¤±è´¥ï¼š{e}"
# è¯»å–æœ¬åœ°æ•°æ®
def load_data():
    try:
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}


# ä¿å­˜æ•°æ®ï¼Œæ”¯æŒæ•°æ®ç´¯åŠ 
def save_data(new_data):
    existing_data = load_data()

    # ç´¯åŠ æ•°æ®
    if "subjects" in existing_data:
        existing_data["subjects"].update(new_data["subjects"])
    else:
        existing_data = new_data

    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=2)


# è§£æå›¾ç‰‡ä¸­çš„é”™é¢˜å†…å®¹
def extract_text_from_image(image):

    if image is None:
        raise ValueError("No image provided. Please upload an image.")

    if isinstance(image, str):  # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„æˆ– URL
        with open(image, "rb") as f:
            image_bytes = f.read()
        img = Image.open(BytesIO(image_bytes))
    else:  # å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡æˆ–å­—èŠ‚æµ
        img = Image.open(BytesIO(image.read()))

    
    reader = easyocr.Reader(['ch_sim'])  # ä½¿ç”¨ç®€ä½“ä¸­æ–‡
    
    # å°†ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆå­—èŠ‚æµï¼‰è½¬ä¸º PIL å›¾åƒ
    img = Image.open(BytesIO(image.read()))  # å°†å­—èŠ‚æµè½¬æ¢ä¸º PIL å›¾åƒ

    # ä½¿ç”¨ easyocr è¯»å–å›¾åƒä¸­çš„æ–‡æœ¬
    result = reader.readtext(img)
    
    text = ""
    for detection in result:
        text += detection[1] + "\n"
    
    return text



# å›¾ç‰‡è½¬æ¢ä¸ºå­—èŠ‚æµçš„è¾…åŠ©å‡½æ•°
def image_to_bytes(image):
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format='PNG')
    return img_byte_arr.getvalue()


# ç”Ÿæˆå­¦ä¹ æŠ¥å‘Šä¸­çš„é¥¼å›¾
def picture(data):
    subjects = data.get("subjects", {})
    report_lines = ["## ğŸ“ å­¦ä¹ æŠ¥å‘Š"]

    # åˆ›å»ºä¸€ä¸ªç©ºçš„ DataFrameï¼Œç”¨äºå±•ç¤ºæ•°æ®
    report_data = []
    subject_names = []
    time_spent_data = []

    for subject, info in subjects.items():
        report_data.append({
            "å­¦ç§‘": subject,
            "å­¦ä¹ æ—¶é—´ (å°æ—¶/å¤©)": info.get("time_spent", 0),
            "é”™é¢˜æè¿°": info.get("mistake", 'æ— '),
            "å­¦ä¹ å¤‡æ³¨": info.get("notes", 'æ— ')
        })
        subject_names.append(subject)
        time_spent_data.append(info.get("time_spent", 0))

    # è‡ªå®šä¹‰æ ‡ç­¾æ˜¾ç¤ºå…·ä½“æ—¶é—´å’Œç™¾åˆ†æ¯”
    def func(pct, allvalues):
        absolute = int(pct / 100.*sum(allvalues))  # è®¡ç®—å…·ä½“æ—¶é—´
        return f"{absolute}å°æ—¶\n({pct:.1f}%)"  # æ ¼å¼åŒ–è¾“å‡º

    # ç»˜åˆ¶åˆå¹¶æ‰€æœ‰ç§‘ç›®å­¦ä¹ æ—¶é—´çš„é¥¼å›¾
    fig, ax = plt.subplots()
    ax.pie(time_spent_data, labels=subject_names, autopct=lambda pct: func(pct, time_spent_data), startangle=50)
    ax.axis('equal')  # ä¿è¯é¥¼å›¾æ˜¯åœ†å½¢çš„
    report_lines.append("### å­¦ä¹ æ—¶é—´åˆ†å¸ƒå›¾")
    
    # å°†å›¾ç‰‡ä¿å­˜åˆ°æ–‡ä»¶å¹¶é€šè¿‡ Streamlit æ˜¾ç¤º
    st.pyplot(fig)  # This will display the pie chart directly


# ä¸»å‡½æ•°
def main():
    st.set_page_config(page_title="å°çŸ¥å­¦ä¼´", layout="wide")
    st.title("ğŸ“ å°çŸ¥å­¦ä¼´ - AIå­¦ä¹ åŠ©æ‰‹")

    menu = st.sidebar.radio("åŠŸèƒ½èœå•", ["è¾“å…¥å­¦ä¹ æ•°æ®", "ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š", "AIç­”ç–‘"])

    if menu == "è¾“å…¥å­¦ä¹ æ•°æ®":
        st.header("ğŸ“¥ è¾“å…¥ä½ çš„å­¦ä¹ æ•°æ®")

        # ç”¨æˆ·è‡ªå®šä¹‰å­¦ç§‘æ•°é‡å’Œåç§°
        num_subjects = st.number_input("è¯·è¾“å…¥å­¦ç§‘æ•°é‡", min_value=1, max_value=10, value=1)

        custom_subjects = []
        for i in range(num_subjects):
            subject_name = st.text_input(f"è¯·è¾“å…¥ç¬¬ {i+1} é—¨å­¦ç§‘åç§°", key=f"subject_{i}")
            custom_subjects.append(subject_name)

        selected_subjects = custom_subjects
        subject_data = {}
        all_mistakes = []

        for subject in selected_subjects:
            st.subheader(f"ğŸ“˜ {subject} å­¦ä¹ æƒ…å†µ")

            uploaded_image = st.file_uploader(f"ä¸Šä¼  {subject} çš„é”™é¢˜å›¾ç‰‡", type=["png", "jpg", "jpeg"],
                                              key=f"{subject}_image")
            extracted_text = ""

            if uploaded_image:
                extracted_text = extract_text_from_image(image)
                st.text_area(f"{subject} è¯†åˆ«å‡ºçš„é”™é¢˜å†…å®¹", extracted_text, key=f"{subject}_ocr_text")

            mistake = st.text_area(f"{subject} çš„é”™é¢˜æè¿°ï¼ˆå¯ç¼–è¾‘ï¼‰", extracted_text, key=f"{subject}_mistake")
            notes = st.text_area(f"{subject} çš„å…¶ä»–å­¦ä¹ å¤‡æ³¨", key=f"{subject}_notes")
            time_spent = st.slider(f"â±ï¸ æ¯å¤©ç”¨äº {subject} çš„å­¦ä¹ æ—¶é—´ï¼ˆå°æ—¶ï¼‰", 0, 12, 1, key=f"{subject}_time")

            if mistake:
                all_mistakes.append(f"{subject}ï¼š{mistake}")

            subject_data[subject] = {
                "mistake": mistake,
                "notes": notes,
                "time_spent": time_spent
            }

        if st.button("ä¿å­˜æ•°æ®"):
            data = {
                "subjects": subject_data
            }
            save_data(data)
            st.success("âœ… æ•°æ®å·²ä¿å­˜ï¼")

        if st.button("æ¸…ç©ºæ‰€æœ‰æ•°æ®"):
            with open(DATA_PATH, "w", encoding="utf-8") as f:
                json.dump({}, f, ensure_ascii=False, indent=2)
            st.success("âœ… æ‰€æœ‰æ•°æ®å·²æ¸…ç©ºï¼")


        # âœ… é”™é¢˜åˆ†æåŒº
        if all_mistakes:
            st.markdown("### ğŸ§  é”™é¢˜åˆ†æ")
            st.write("ä½ å·²è¾“å…¥ä»¥ä¸‹é”™é¢˜ï¼š")
            for i, m in enumerate(all_mistakes, 1):
                st.write(f"{i}. {m}")

            if st.button("åˆ†ææˆ‘çš„é”™é¢˜"):
                with st.spinner("æ­£åœ¨åˆ†æä¸­..."):
                    mistake_text = "\n".join(all_mistakes)
                    response = analyze_mistakes_with_kimi(mistake_text)
                    st.markdown("#### ğŸ“Š Kimi åˆ†æç»“æœ")
                    st.write(response)

    elif menu == "ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š":
        st.header("ğŸ“Š AIç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ æŠ¥å‘Š")
        data = load_data()
        if data:
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                picture(data)
                report = generate_learning_report(data)
                st.markdown(report)
        else:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§å¡«å†™å­¦ä¹ æ•°æ®")


 # AIç­”ç–‘éƒ¨åˆ†
    elif menu == "AIç­”ç–‘":
    
        st.header("ğŸ§‘â€ğŸ« æé—®ä»»æ„å­¦ä¹ é—®é¢˜")
    
        # ä¸Šä¼ é—®é¢˜å›¾ç‰‡
        uploaded_image = st.file_uploader("ä¸Šä¼ é—®é¢˜å›¾ç‰‡", type=["png", "jpg", "jpeg"], key="question_image")
        
        # è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡æœ¬
        extracted_question_text = ""
        if uploaded_image:
            # æå–å›¾ç‰‡ä¸­çš„æ–‡æœ¬
            extracted_question_text = extract_text_from_image(image)
            st.text_area("è¯†åˆ«å‡ºçš„é—®é¢˜", extracted_question_text, key="question_ocr_text")
    
        # ç”¨æˆ·è¾“å…¥é—®é¢˜æ–‡æœ¬
        question = st.text_area("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆå¯ç¼–è¾‘ï¼‰", extracted_question_text)
    
        if st.button("AIå›ç­”"):
            # å¦‚æœæ²¡æœ‰ä¸Šä¼ å›¾ç‰‡ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
            if not question and extracted_question_text:
                question = extracted_question_text  # å¦‚æœæ²¡æœ‰è¾“å…¥ï¼Œä½¿ç”¨å›¾ç‰‡ä¸­çš„æ–‡æœ¬
    
            if question:
                with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                    # ä½¿ç”¨ Kimi API è·å–å›ç­”
                    reply = ask_kimi(question)
                    st.markdown("**AIç­”å¤ï¼š**")
                    st.write(reply)
            else:
                st.warning("è¯·è¾“å…¥æˆ–ä¸Šä¼ é—®é¢˜å›¾ç‰‡ä»¥è·å–ç­”æ¡ˆã€‚")



if __name__ == '__main__':
    main()
